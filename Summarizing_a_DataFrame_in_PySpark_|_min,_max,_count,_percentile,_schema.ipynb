{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizing a DataFrame in PySpark | min, max, count, percentile, schema.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMin2tm33afiJiZiFS3/yI8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GauravSahani1417/PySpark-Basic-Implementation/blob/main/Summarizing_a_DataFrame_in_PySpark_%7C_min%2C_max%2C_count%2C_percentile%2C_schema.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ2JdvP4EYtw",
        "outputId": "3349b823-1d7f-47aa-8eb3-523a0ed1135e"
      },
      "source": [
        "# Setting up the PySpark environment\n",
        "\n",
        "# Install java 8\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Apache Spark binary: This link can change based on the version. Update this link with the latest version before using\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Unzip file\n",
        "!tar -xf spark-3.0.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark: Adds Pyspark to sys.path at runtime\n",
        "!pip install -q findspark\n",
        "\n",
        "# Install pyspark\n",
        "!pip install pyspark\n",
        "\n",
        "# Add environmental variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\n",
        "\n",
        "# findspark will locate spark in the system\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,414 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,184 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [450 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,770 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,616 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [480 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Fetched 12.4 MB in 3s (3,919 kB/s)\n",
            "Reading package lists... Done\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 62kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=a80379e10af9c37a96e8f13b30fc1b09e75e8b61614f4abed791a01822fdba5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyobdMJVGjdd"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local\") \\\n",
        "        .appName(\"Hands-on PySpark on Google Colab\") \\\n",
        "        .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "80US235OGmfM",
        "outputId": "59fecc93-5ce1-4518-9f5c-7ea5325407a2"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c508bd20bd11:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Hands-on PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7fa84d6110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9Ad63DGo_x"
      },
      "source": [
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00603/in-vehicle-coupon-recommendation.csv -P sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fSHfaAXGuG1",
        "outputId": "14a670f8-9020-4208-9072-221d9602d24c"
      },
      "source": [
        "# We can set header='true' and inferSchema='true' to infer the schema while reading the data\n",
        "\n",
        "filepath = \"sample_data/in-vehicle-coupon-recommendation.csv\"\n",
        "spark_df = spark.read.format('csv').options(header='true', inferSchema='true').load(filepath)\n",
        "spark_df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "|destination    |passanger|weather|temperature|time|coupon               |expiration|gender|age|maritalStatus    |has_children|education               |occupation|income         |car |Bar  |CoffeeHouse|CarryAway|RestaurantLessThan20|Restaurant20To50|toCoupon_GEQ5min|toCoupon_GEQ15min|toCoupon_GEQ25min|direction_same|direction_opp|Y  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "|No Urgent Place|Alone    |Sunny  |55         |2PM |Restaurant(<20)      |1d        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |0                |0                |0             |1            |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Coffee House         |2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |0                |0                |0             |1            |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Carry out & Take away|2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |1d        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |0  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aYe5bDMGyZe",
        "outputId": "2cd9610b-3dbd-49e8-c169-9b15475cb23c"
      },
      "source": [
        "len(spark_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpHnE1y8G8U3",
        "outputId": "285871a1-8c45-4d1d-cd9a-0608c0db1676"
      },
      "source": [
        "#Selecting 9/26 columns\n",
        "columns_to_use = [\"destination\", \"passanger\", \"weather\", \"temperature\", \"time\", \"coupon\", \"gender\", \"age\", \"has_children\", \"toCoupon_GEQ5min\", \"Y\"]\n",
        "spark_df = spark_df.select(*columns_to_use)\n",
        "spark_df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "|destination    |passanger|weather|temperature|time|coupon               |gender|age|has_children|toCoupon_GEQ5min|Y  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "|No Urgent Place|Alone    |Sunny  |55         |2PM |Restaurant(<20)      |Female|21 |1           |1               |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Coffee House         |Female|21 |1           |1               |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Carry out & Take away|Female|21 |1           |1               |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |Female|21 |1           |1               |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |Female|21 |1           |1               |0  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0VaDQshHfFf",
        "outputId": "7250605a-0dae-4d41-9b29-2e4359c9309a"
      },
      "source": [
        "spark_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgOzuxniHlNZ",
        "outputId": "95ef9b92-fcaf-4a04-fca7-b18a5d56d3ea"
      },
      "source": [
        "print(spark_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon', 'gender', 'age', 'has_children', 'toCoupon_GEQ5min', 'Y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQm9YCaxHnWi",
        "outputId": "589bcf8f-a25a-48e5-a03d-30a4c4706bf6"
      },
      "source": [
        "len(spark_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZQQocqYHpoG",
        "outputId": "2ddec89c-4d33-4644-99fa-ab1cdadd395b"
      },
      "source": [
        "spark_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- destination: string (nullable = true)\n",
            " |-- passanger: string (nullable = true)\n",
            " |-- weather: string (nullable = true)\n",
            " |-- temperature: integer (nullable = true)\n",
            " |-- time: string (nullable = true)\n",
            " |-- coupon: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- has_children: integer (nullable = true)\n",
            " |-- toCoupon_GEQ5min: integer (nullable = true)\n",
            " |-- Y: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoEQ1N23Ht1W",
        "outputId": "4a10cb1d-1d07-4cf5-8f20-f4632a06b100"
      },
      "source": [
        "spark_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('destination', 'string'),\n",
              " ('passanger', 'string'),\n",
              " ('weather', 'string'),\n",
              " ('temperature', 'int'),\n",
              " ('time', 'string'),\n",
              " ('coupon', 'string'),\n",
              " ('gender', 'string'),\n",
              " ('age', 'string'),\n",
              " ('has_children', 'int'),\n",
              " ('toCoupon_GEQ5min', 'int'),\n",
              " ('Y', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y85IYXNNH1X1"
      },
      "source": [
        "Describe the dataframe (min, max, count)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0OYgR4bHxOh",
        "outputId": "45f1a089-b190-420e-c642-a7ae39112eae"
      },
      "source": [
        "spark_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, destination: string, passanger: string, weather: string, temperature: string, time: string, coupon: string, gender: string, age: string, has_children: string, toCoupon_GEQ5min: string, Y: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79E0CCwDH33B",
        "outputId": "c06df50e-2275-486f-dbf2-97d2b4365d82"
      },
      "source": [
        "# To get the output, you have to run action commands (like show, collect, etc.)\n",
        "spark_df.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|summary|destination|passanger|weather|       temperature| time|         coupon|gender|               age|      has_children|toCoupon_GEQ5min|                 Y|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|  count|      12684|    12684|  12684|             12684|12684|          12684| 12684|             12684|             12684|           12684|             12684|\n",
            "|   mean|       null|     null|   null|63.301797540208135| null|           null|  null|29.887815247850035|0.4141438032166509|             1.0|0.5684326710816777|\n",
            "| stddev|       null|     null|   null| 19.15448575684057| null|           null|  null| 7.697275065801651|   0.4925929797555|             0.0| 0.495314356461186|\n",
            "|    min|       Home|    Alone|  Rainy|                30| 10AM|            Bar|Female|                21|                 0|               1|                 0|\n",
            "|    max|       Work|  Partner|  Sunny|                80|  7AM|Restaurant(<20)|  Male|           below21|                 1|               1|                 1|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojkGH4HILRu"
      },
      "source": [
        "Percentiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylUpSkP1IKvu",
        "outputId": "85c0294d-8388-4720-a9c7-97cf22ca854e"
      },
      "source": [
        "spark_df.summary().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|summary|destination|passanger|weather|       temperature| time|         coupon|gender|               age|      has_children|toCoupon_GEQ5min|                 Y|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|  count|      12684|    12684|  12684|             12684|12684|          12684| 12684|             12684|             12684|           12684|             12684|\n",
            "|   mean|       null|     null|   null|63.301797540208135| null|           null|  null|29.887815247850035|0.4141438032166509|             1.0|0.5684326710816777|\n",
            "| stddev|       null|     null|   null| 19.15448575684057| null|           null|  null| 7.697275065801651|   0.4925929797555|             0.0| 0.495314356461186|\n",
            "|    min|       Home|    Alone|  Rainy|                30| 10AM|            Bar|Female|                21|                 0|               1|                 0|\n",
            "|    25%|       null|     null|   null|                55| null|           null|  null|              21.0|                 0|               1|                 0|\n",
            "|    50%|       null|     null|   null|                80| null|           null|  null|              26.0|                 0|               1|                 1|\n",
            "|    75%|       null|     null|   null|                80| null|           null|  null|              36.0|                 1|               1|                 1|\n",
            "|    max|       Work|  Partner|  Sunny|                80|  7AM|Restaurant(<20)|  Male|           below21|                 1|               1|                 1|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItnNr5KAICCB",
        "outputId": "996891e5-7c84-49b3-921a-3a55d88c931b"
      },
      "source": [
        "#Custom percentile summary!\n",
        "spark_df.summary(\"40%\", \"60%\", \"90%\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "|summary|destination|passanger|weather|temperature|time|coupon|gender| age|has_children|toCoupon_GEQ5min|  Y|\n",
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "|    40%|       null|     null|   null|         55|null|  null|  null|26.0|           0|               1|  0|\n",
            "|    60%|       null|     null|   null|         80|null|  null|  null|31.0|           1|               1|  1|\n",
            "|    90%|       null|     null|   null|         80|null|  null|  null|41.0|           1|               1|  1|\n",
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRdTaky-Igdu"
      },
      "source": [
        "Hence, We have seen how to extract basic statistics from a DataFrame using PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP9sFSFIVFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}